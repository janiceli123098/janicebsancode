{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy of 05-starter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janiceli123098/janicebsancode/blob/janiceli123098-MGMT6560_IntroML/hm05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa2oR692bSwe",
        "colab_type": "text"
      },
      "source": [
        "## Homework 05 - Instructions\n",
        "\n",
        "![](https://github.com/rpi-techfundamentals/hm-01-starter/blob/master/notsaved.png?raw=1)\n",
        "\n",
        "**WARNING!!!  If you see this icon on the top of your COLAB sesssion, your work is not saved automatically.**\n",
        "\n",
        "\n",
        "**When you are working on homeworks, make sure that you save often. You may find it easier to save intermident copies in Google drive. If you save your working file in Google drive all changes will be saved as you work. MAKE SURE that your final version is saved to GitHub.** \n",
        "\n",
        "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All).  You can speak with others regarding the assignment but all work must be your own. \n",
        "\n",
        "\n",
        "### This is a 30 point assignment graded from answers to questions and automated tests that should be run at the bottom. Be sure to clearly label all of your answers and commit final tests at the end.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sHwHAexbSwj",
        "colab_type": "code",
        "outputId": "000be6ee-2eb0-4a79-ebc8-5cfbe1176da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "files = \"https://github.com/rpi-techfundamentals/hm-05-starter/raw/master/files.zip\" \n",
        "!rm -rf * && pip install git+https://github.com/data-8/Gofer-Grader && wget $files && unzip -o files.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/data-8/Gofer-Grader\n",
            "  Cloning https://github.com/data-8/Gofer-Grader to /tmp/pip-req-build-qr45by53\n",
            "  Running command git clone -q https://github.com/data-8/Gofer-Grader /tmp/pip-req-build-qr45by53\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from gofer-grader==1.0.9) (2.10.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from gofer-grader==1.0.9) (2.1.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from gofer-grader==1.0.9) (4.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->gofer-grader==1.0.9) (1.1.1)\n",
            "Building wheels for collected packages: gofer-grader\n",
            "  Building wheel for gofer-grader (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gofer-grader: filename=gofer_grader-1.0.9-cp36-none-any.whl size=10115 sha256=c19914e6be0adabda18c68ffb4218fff7083f638609d68ed0204f6bf5ed48fbc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f_stox59/wheels/9e/62/24/8563ae039051d6ba979557d1766bfebbda5dd08f8572e3e35d\n",
            "Successfully built gofer-grader\n",
            "Installing collected packages: gofer-grader\n",
            "Successfully installed gofer-grader-1.0.9\n",
            "--2019-10-02 02:31:56--  https://github.com/rpi-techfundamentals/hm-05-starter/raw/master/files.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rpi-techfundamentals/hm-05-starter/master/files.zip [following]\n",
            "--2019-10-02 02:31:56--  https://raw.githubusercontent.com/rpi-techfundamentals/hm-05-starter/master/files.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48906 (48K) [application/zip]\n",
            "Saving to: ‘files.zip’\n",
            "\n",
            "files.zip           100%[===================>]  47.76K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-10-02 02:31:56 (3.00 MB/s) - ‘files.zip’ saved [48906/48906]\n",
            "\n",
            "Archive:  files.zip\n",
            "  inflating: train-new.csv           \n",
            "  inflating: test-new.csv            \n",
            "   creating: tests/\n",
            "  inflating: tests/q01.py            \n",
            "  inflating: tests/q05.py            \n",
            " extracting: tests/__init__.py       \n",
            "  inflating: tests/q03.py            \n",
            "  inflating: tests/q02.py            \n",
            "  inflating: tests/q06.py            \n",
            "   creating: tests/.ipynb_checkpoints/\n",
            "  inflating: hm.ok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be8RV86FbSwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run this. It initiates autograding. \n",
        "from client.api.notebook import Notebook\n",
        "ok = Notebook('lab.ok')\n",
        "_ = ok.auth(inline=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg8hCPMcbSwx",
        "colab_type": "text"
      },
      "source": [
        "### Load Data\n",
        "We have our titanic dataset that is a bit different from what we have had previously. Load the train-new.csv and test-new.csv into dataframes train and test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb87SMGdbSwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data here\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "# Input data files from current directory.\n",
        "# Let's input them into a Pandas DataFrame\n",
        "train = pd.read_csv(\"train-new.csv\")\n",
        "test  = pd.read_csv(\"test-new.csv\")\n",
        "\n",
        "#!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8X3qovbT9DM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print('train', train.index, train.columns, train.dtypes)\n",
        "#print('test', test.index, test.columns, test.dtypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUqcaFFyVk7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHJUWnmSbSw2",
        "colab_type": "text"
      },
      "source": [
        "## Question 1\n",
        "(1) Investigate the data a little bit. What is different from some of the titanic datasets we have used in the past? (For example, compare against the data in the Kaggle Baseline notebook). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSwkhRl8bSw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "man1=\"\"\"\n",
        "\n",
        "- Data from the Kaggle Baseline notebook, I can capture column labels and rows range for both test and train.\n",
        "\n",
        "train RangeIndex(start=0, stop=891, step=1) Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
        "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
        "      dtype='object')\n",
        "test RangeIndex(start=0, stop=418, step=1) Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
        "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'Survived', 'PredGender'],\n",
        "      dtype='object')\n",
        "\n",
        "- Data this time, I still capture column labels and rows range for both test and train.\n",
        "train RangeIndex(start=0, stop=891, step=1) Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
        "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'family_size'],\n",
        "      dtype='object')\n",
        "test RangeIndex(start=0, stop=891, step=1) Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
        "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'family_size'],\n",
        "      dtype='object')\n",
        "\n",
        "- Comparing above outputs, i find two points that Titanic datasets we use this time are different from the past:\n",
        "1. This time, both train and test datasets have 891 rows, and their columns labels (attributes) are the same.\n",
        "2. There are two columns added in datasets this time, 'Title' and 'family_size'. Their data types are\n",
        "   Title           object\n",
        "   family_size      int64\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkUmCuSBbSw_",
        "colab_type": "text"
      },
      "source": [
        "# Generating Dummy Variables\n",
        "Before we do analysis of the titanic dataset, we have to select out our features, for the train and the test set, which we shall label `X_train`, and `X_test`.\n",
        "\n",
        "As a part of this we need to generate `n-1` dummy variables for each one of our categorical columns.  The resulting dataframes should be all numeric and have all of these columns below (in the correct order).\n",
        "\n",
        "Follow the example above to generate a new value for `X` utilizing all the data.\n",
        "```\n",
        "['Age', 'SibSp', 'Parch', 'Fare', 'family_size', 'Pclass_2', 'Pclass_3', 'Sex_male', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_H', 'Embarked_Q', 'Embarked_S']\n",
        "\n",
        "```\n",
        "*Hint, try: \n",
        "`help(pd.get_dummies)`* \n",
        "\n",
        "You should also set `y` to the Survived column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZS4t2IEbSxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Answer Here \n",
        "\n",
        "# X_train\n",
        "feature_1_train = train[['Age', 'SibSp', 'Parch', 'Fare', 'family_size']]\n",
        "feature_model_1_train = pd.get_dummies(feature_1_train)\n",
        "\n",
        "feature_2_train = train['Pclass']\n",
        "feature_model_2_train = pd.get_dummies(feature_2_train, prefix = 'Pclass', drop_first = True)\n",
        "\n",
        "features_train = train[['Sex', 'Cabin', 'Embarked']]\n",
        "features_model_train = pd.get_dummies(features_train, drop_first=True)\n",
        "\n",
        "X_train = pd.concat([feature_model_1_train, feature_model_2_train, features_model_train], axis = 1, join = 'outer')\n",
        "\n",
        "# X_test\n",
        "feature_1_test = test[['Age', 'SibSp', 'Parch', 'Fare', 'family_size']]\n",
        "feature_model_1_test = pd.get_dummies(feature_1_test)\n",
        "\n",
        "feature_2_test = test['Pclass']\n",
        "feature_model_2_test = pd.get_dummies(feature_2_test, prefix = 'Pclass', drop_first = True)\n",
        "\n",
        "features_test = test[['Sex', 'Cabin', 'Embarked']]\n",
        "features_model_test = pd.get_dummies(features_test, drop_first=True)\n",
        "\n",
        "X_test = pd.concat([feature_model_1_test, feature_model_2_test, features_model_test], axis = 1, join = 'outer')\n",
        "\n",
        "# set y to the Survived column.\n",
        "y = train['Survived']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keR4XLydbSxG",
        "colab_type": "code",
        "outputId": "8b4d8a3e-2db5-4fcf-825f-5169190434a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "_ = ok.grade('q01')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "<gofer.ok.OKTestsResult at 0x7f3f7ddb3c88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-JWvEwKbSxL",
        "colab_type": "text"
      },
      "source": [
        "## Split Training Set For Cross Validation\n",
        "(2.) We want to split up our training set `X` so that we can do some cross validation. Specifically, we will start to use the term validation set for the \n",
        "\n",
        "In doing below, use the sklearn methods to to a train test (i.e., validation) split.  \n",
        "\n",
        "From X y dataframe, generate the following dataframes by drawing the data **randomly**  from the train dataframe 80% of the data in train and 20% of the data in test.  So that you get repeatable results, set the `random_state=100`. This will set a \"seed\" so that your random selection will be the same as mine and you will pass the internal tests. \n",
        "\n",
        "train_X, val_X, train_y, val_y\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGR_kAidbSxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Answer Here\n",
        "\n",
        "#Import Module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = X_train\n",
        "\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y, \n",
        "                                                    train_size=0.8,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImFXwN5FbSxP",
        "colab_type": "code",
        "outputId": "b65d2499-83cc-49ae-b995-1a71f6ca5141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "_ = ok.grade('q02')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "<gofer.ok.OKTestsResult at 0x7f3f7f051470>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKuHoBR4bSxT",
        "colab_type": "text"
      },
      "source": [
        "### Perform Nearest Neighbor Classification (KNeighborsClassifier)\n",
        "(3.) Using the default options (i.e., all default hyperparameters), perform nearest neighbor classification. Calculate the accuracy measure using `metrics.accuracy_score`.\n",
        "\n",
        "Train your model using the training data and access the accuracy of both the training and validation data.\n",
        "\n",
        "*Note: You only train the model once...on the training data. You then assess the performance on both the training and validation data.*\n",
        "\n",
        "Assign the following variables:\n",
        "\n",
        "`knn0_train_y` = The KNN prediction for the `train_X` data. \n",
        "\n",
        "`knn0_val_y`   = The KNN prediction for the `val_X` data. \n",
        "\n",
        "`knn0_train_accuracy` = The accuracy for the `knn0_train_y` prediction. \n",
        "\n",
        "`knn0_val_accuracy` = The accuracy for the `knn0_val_y` prediction. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihtkWAZibSxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Answer Here \n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "#This creates a model object.\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "#This fits the model object to the data.\n",
        "knn.fit(train_X, train_y)\n",
        "\n",
        "#This creates the prediction. \n",
        "knn0_train_y = knn.predict(train_X)\n",
        "knn0_val_y = knn.predict(val_X)\n",
        "\n",
        "knn0_train_accuracy = metrics.accuracy_score(train_y, knn0_train_y)\n",
        "knn0_val_accuracy = metrics.accuracy_score(val_y, knn0_val_y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWAVd2CjbSxV",
        "colab_type": "code",
        "outputId": "324b0432-d836-4ff7-8745-353c307765ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "_ = ok.grade('q03')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "<gofer.ok.OKTestsResult at 0x7f3f7f119518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjcpHG9AbSxX",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix\n",
        "We can utilize a confusion matrix to be able to understand misclassifications a bit more. This will give us a full idea of the true positives, true negatives, false positives, and false negatives.  \n",
        "\n",
        "See the documentation [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). \n",
        "\n",
        "You can utilize the syntax below to generate knn_mat1_train and knn_mat1_test.  \n",
        "```\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_true, y_pred)\n",
        "```\n",
        "**(4.)  Explain what each of the four quadrants of the confusion matrix means. **\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECuu7swwbSxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Answer here\n",
        "man4= \"\"\"\n",
        "\n",
        "> First, take an easy example to help understand what is the meaning of each quadrant of the confusion matrix\n",
        "\n",
        "--input--\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\"]\n",
        "y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\"]\n",
        "\n",
        "confusion_matrix(y_true, y_pred)\n",
        "\n",
        "--output--\n",
        "array([[2, 0],\n",
        "       [1, 2]])\n",
        "\n",
        "Based on output, I can draw these conclusions:\n",
        "C(0,0) = 2, which means there are 2 observations in the list that are known to be 'cat' and predicted to be 'cat' \n",
        "C(0,1) = 0, which means there is 0 observation that is known to be 'ant' and predicted to be 'cat'\n",
        "C(1,0) = 1, which means there is 1 observation that is known to be 'cat' and predicted to be 'ant'\n",
        "C(1,1) = 2, which means there are 2 observations that are known to be 'ant' and predicted to be 'ant'\n",
        "\n",
        "That is to say, C(0,0) and C(1,1) are the count of right classsfications, while C(0,1) and C(1,0) are misclassifications.\n",
        "\n",
        "> In our case, i run below command to check the confusion matrix for the training data and get an output.\n",
        "\n",
        "knn0_con_train = confusion_matrix(train_y, knn0_train_y)\n",
        "=[[389  56]\n",
        " [ 82 185]]\n",
        "\n",
        "So there are 389 observations that truly not survived and were predicted to be 'not-survived';\n",
        "there are 56 observations that do survive but were predicted to be 'not-survived';\n",
        "there are 82 observations that not survived but were predicted to be 'survived';\n",
        "there are 185 observations that do survive and were predicted to be 'survived'.\n",
        "\n",
        "There are 389+185 observations that were predicted correctly for the training data.\n",
        "Accuracy of prediction can be calculated, which is the same value as knn0_train_accuracy we calculated before.\n",
        "\n",
        "accuracy_training_data = (389+185)/len(train_y) = 574/712 = 0.806179775\n",
        "knn0_train_accuracy = 0.8061797752808989\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIt4TsyDbSxZ",
        "colab_type": "text"
      },
      "source": [
        "### Create Confusion Matrix for the Training and Validation Predictions\n",
        "(5) Create a confusion matrix for each of the training and valiation predictions. \n",
        "`knn0_con_train` A confusion matrix for the training data.  \n",
        "`knn0_con_val` A confusion matrix for the validation data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71IIXjzkbSxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Answers \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "knn0_con_train = confusion_matrix(train_y, knn0_train_y)\n",
        "\n",
        "knn0_con_val = confusion_matrix(val_y, knn0_val_y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf7tSj7GbSxc",
        "colab_type": "code",
        "outputId": "98225cda-eb2a-4221-e11f-0c4b39f86e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "_ = ok.grade('q05')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "<gofer.ok.OKTestsResult at 0x7f3f7ddb3d30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Coy4lZEbSxg",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameter Tuning\n",
        "\n",
        "(6) You created a single model using the default parameters.  However, we want to adjust the parameters to try and improve the model.  \n",
        "\n",
        "Examine the documentation on KNN and see some of the different parameters that you can adjust. \n",
        "\n",
        "[Scikit Learn Documentation](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning).\n",
        "\n",
        "Assign the following variables:\n",
        "\n",
        "`knn1_train_y` = The KNN prediction for the `train_X` datafor your improved model. \n",
        "\n",
        "`knn1_val_y`   = The KNN prediction for the `val_X` data for your improved model. \n",
        "\n",
        "`knn1_train_accuracy` = The accuracy for the `knn1_train_y` prediction. \n",
        "\n",
        "`knn1_val_accuracy` = The accuracy for the `knn1_val_y` prediction. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNjeBvXmbSxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Answers\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#This creates a model object.\n",
        "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "#This fits the model object to the data.\n",
        "knn1.fit(train_X, train_y)\n",
        "\n",
        "#This creates the prediction. \n",
        "knn1_train_y = knn1.predict(train_X)\n",
        "knn1_val_y = knn1.predict(val_X)\n",
        "\n",
        "knn1_train_accuracy = knn1.score(train_X, train_y)\n",
        "knn1_val_accuracy = knn1.score(val_X, val_y)\n",
        "\n",
        "#print(knn0_train_accuracy, knn1_train_accuracy, '\\n', knn0_val_accuracy, knn1_val_accuracy)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AydjFz3RbSxi",
        "colab_type": "code",
        "outputId": "0bc71cc8-d3ac-4a81-eb9c-27a5f5879b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "_ = ok.grade('q06')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "<gofer.ok.OKTestsResult at 0x7f3f7ddb3b38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YolPWFYabSxk",
        "colab_type": "text"
      },
      "source": [
        "### Other Models\n",
        "\n",
        "(7.) Test Logistic regression and 1 other algorithms/models (your choice).  Provide a summary of the best performance below. \n",
        "\n",
        "Use any of the available classification models. You should show and comment code\n",
        "\n",
        "[Scikit Learn Documentation](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning).\n",
        "\n",
        "*Make sure your clearly indicate the accuracy of the Logistic regression model your other model. Assess which model worked best considering all your efforts.*\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1_reD4BbSxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Answer here\n",
        "man7= \"\"\"\n",
        "\n",
        "I create a new code session below to test Logistic regression and another model I choose, which is Support Vector Machine.\n",
        "\n",
        "########################## Code ##########################\n",
        "#######Test Logistic regression#######\n",
        "# import package\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# create a model object\n",
        "lr = LogisticRegression(solver='newton-cg')\n",
        "\n",
        "# fit the model object to the train data\n",
        "lr.fit(train_X, train_y)\n",
        "\n",
        "# create the predictions for both train data and validation data\n",
        "lr_train_y = lr.predict(train_X)\n",
        "lr_val_Y = lr.predict(val_X)\n",
        "\n",
        "# calculate the accuracy\n",
        "lr_train_accuracy = lr.score(train_X, train_y)\n",
        "lr_val_accuracy = lr.score(val_X, val_y)\n",
        "\n",
        "#######Test Support Vector Machines (SVM)#######\n",
        "# import package\n",
        "from sklearn import svm\n",
        "\n",
        "# create a model object\n",
        "svm0 = svm.SVC(gamma='auto', decision_function_shape='ovo')\n",
        "\n",
        "# fit the model object to the train data\n",
        "svm0.fit(train_X, train_y)\n",
        "\n",
        "# create the predictions for both train data and validation data\n",
        "svm0_train_y = svm0.predict(train_X)\n",
        "svm0_val_Y = svm0.predict(val_X)\n",
        "\n",
        "# calculate the accuracy\n",
        "svm0_train_accuracy = svm0.score(train_X, train_y)\n",
        "svm0_val_accuracy = svm0.score(val_X, val_y)\n",
        "\n",
        "#######Summary of all the models tested#######\n",
        "# compare these models and output the results\n",
        "import pandas as pd\n",
        "\n",
        "result = [{'train_accuracy': knn0_train_accuracy, 'val_accuracy': knn0_val_accuracy },\n",
        "          {'train_accuracy': knn1_train_accuracy, 'val_accuracy': knn1_val_accuracy },\n",
        "          {'train_accuracy': lr_train_accuracy, 'val_accuracy': lr_val_accuracy},\n",
        "          {'train_accuracy': svm0_train_accuracy, 'val_accuracy': svm0_val_accuracy}]\n",
        "result_set = pd.DataFrame(result)\n",
        "result_set.index = ['knn0', 'knn1', 'lr', 'svm0']\n",
        "print(result_set)\n",
        "\n",
        "########################## Code output ##########################\n",
        "      train_accuracy  val_accuracy\n",
        "knn0        0.806180      0.675978\n",
        "knn1        0.992978      0.715084\n",
        "lr          0.824438      0.804469\n",
        "svm0        0.867978      0.675978\n",
        "\n",
        "########################## Summary ##########################\n",
        "Based on the models we use and parameters using to fit the model, I can get above results.\n",
        "According to the result, KNN model setting n_neighbors=1 performs best for the training data, with 99% accuracy, while logistic regression solver='newton-cg' preforms\n",
        "best for the validation data after it was fit to the train data, with 80% accuracy.\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG0HiLvHaP2X",
        "colab_type": "code",
        "outputId": "4c52f517-b5dc-417c-bc3d-fe77d7e1113c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "####### Test Logistic regression #######\n",
        "# import package\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# create a model object\n",
        "lr = LogisticRegression(solver='newton-cg')\n",
        "\n",
        "# fit the model object to the train data\n",
        "lr.fit(train_X, train_y)\n",
        "\n",
        "# create the predictions for both train data and validation data\n",
        "lr_train_y = lr.predict(train_X)\n",
        "lr_val_Y = lr.predict(val_X)\n",
        "\n",
        "# calculate the accuracy\n",
        "lr_train_accuracy = lr.score(train_X, train_y)\n",
        "lr_val_accuracy = lr.score(val_X, val_y)\n",
        "\n",
        "####### Test Support Vector Machines (SVM) #######\n",
        "# import package\n",
        "from sklearn import svm\n",
        "\n",
        "# create a model object\n",
        "svm0 = svm.SVC(gamma='auto', decision_function_shape='ovo')\n",
        "\n",
        "# fit the model object to the train data\n",
        "svm0.fit(train_X, train_y)\n",
        "\n",
        "# create the predictions for both train data and validation data\n",
        "svm0_train_y = svm0.predict(train_X)\n",
        "svm0_val_Y = svm0.predict(val_X)\n",
        "\n",
        "# calculate the accuracy\n",
        "svm0_train_accuracy = svm0.score(train_X, train_y)\n",
        "svm0_val_accuracy = svm0.score(val_X, val_y)\n",
        "\n",
        "####### Summary of all the models tested #######\n",
        "# compare these models and output the results\n",
        "import pandas as pd\n",
        "\n",
        "result = [{'train_accuracy': knn0_train_accuracy, 'val_accuracy': knn0_val_accuracy },\n",
        "          {'train_accuracy': knn1_train_accuracy, 'val_accuracy': knn1_val_accuracy },\n",
        "          {'train_accuracy': lr_train_accuracy, 'val_accuracy': lr_val_accuracy},\n",
        "          {'train_accuracy': svm0_train_accuracy, 'val_accuracy': svm0_val_accuracy}]\n",
        "result_set = pd.DataFrame(result)\n",
        "result_set.index = ['knn0', 'knn1', 'lr', 'svm0']\n",
        "print(result_set)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      train_accuracy  val_accuracy\n",
            "knn0        0.806180      0.675978\n",
            "knn1        0.992978      0.715084\n",
            "lr          0.824438      0.804469\n",
            "svm0        0.867978      0.675978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxqji0eEbSxn",
        "colab_type": "code",
        "outputId": "bee56895-8b58-44fe-b119-824940e1de58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "#This runs all tests. \n",
        "import os\n",
        "_ = [ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q')]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "<gofer.ok.OKTestsResult at 0x7f3f72d571d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "<gofer.ok.OKTestsResult at 0x7f3f72d57550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "<gofer.ok.OKTestsResult at 0x7f3f72d576d8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "<gofer.ok.OKTestsResult at 0x7f3f72d572e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ],
            "text/plain": [
              "<gofer.ok.OKTestsResult at 0x7f3f72d57080>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}